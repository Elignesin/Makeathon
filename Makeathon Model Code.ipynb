{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SprNZO78EH9q"
   },
   "source": [
    "### Makeathon Model Building\n",
    "\n",
    "This notebook is for building the model for our makeathon prompt. This notebook will follow vaguely the tutorial found at https://medium.com/swlh/emotion-detection-using-opencv-and-keras-771260bbd7f7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bDpj3XrSEDni"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation,Flatten,BatchNormalization\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.optimizers import RMSprop,SGD,Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.utils import to_categorical\n",
    "from keras.regularizers import l2\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vT202olbIPDJ"
   },
   "outputs": [],
   "source": [
    "#Now for some definitions we need for later\n",
    "num_classes=7\n",
    "img_rows,img_cols=48,48\n",
    "batch_size= 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wlLEpiLBLJo8"
   },
   "outputs": [],
   "source": [
    "#Create image generators for image augmentation and rescaling for both train and validation datasets\n",
    "train_datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # dimesion reduction\n",
    "        rotation_range=30,  # randomly rotate images in the range 20 degrees\n",
    "        zoom_range = 0.2, # Randomly zoom image 20%\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally 10%\n",
    "        height_shift_range=0.1,  # randomly shift images vertically 10%\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "#(\n",
    "#    rotation_range=40,\n",
    "#    shear_range=0.3,\n",
    "#    zoom_range=0.3,\n",
    "#    width_shift_range=0.4,\n",
    "#    height_shift_range=0.4,\n",
    "#    horizontal_flip=True,\n",
    "#    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 57408,
     "status": "ok",
     "timestamp": 1614719386637,
     "user": {
      "displayName": "Eli Gnesin",
      "photoUrl": "",
      "userId": "07665627688771215674"
     },
     "user_tz": 300
    },
    "id": "bIulAURqLREU",
    "outputId": "8765609a-604d-45e5-d029-372f9852827a"
   },
   "outputs": [],
   "source": [
    "#Read in and prep all the data\n",
    "def prepare_data(data): \n",
    "    image_array = np.zeros(shape=(len(data), 48, 48))\n",
    "    image_label = np.array(list(map(int, data['emotion'])))\n",
    "    \n",
    "    for i, row in enumerate(data.index):\n",
    "        image = np.fromstring(data.loc[row, 'pixels'], dtype=int, sep=' ')\n",
    "        image = np.reshape(image, (48, 48))\n",
    "        image_array[i] = image\n",
    "        \n",
    "    return image_array, image_label\n",
    "\n",
    "data = pd.read_csv('fer2013.csv')\n",
    "\n",
    "train_image_array, train_image_label = prepare_data(data[data['Usage']=='Training'])\n",
    "val_image_array, val_image_label = prepare_data(data[data['Usage']=='PrivateTest'])\n",
    "test_image_array, test_image_label = prepare_data(data[data['Usage']=='PublicTest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_image_array.reshape((train_image_array.shape[0], 48, 48, 1))\n",
    "X_train = train_images.astype('float32')/255\n",
    "val_images = val_image_array.reshape((val_image_array.shape[0], 48, 48, 1))\n",
    "X_val = val_images.astype('float32')/255\n",
    "test_images = test_image_array.reshape((test_image_array.shape[0], 48, 48, 1))\n",
    "X_test = test_images.astype('float32')/255\n",
    "\n",
    "y_train = to_categorical(train_image_label)\n",
    "y_val = to_categorical(val_image_label)\n",
    "y_test = to_categorical(test_image_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit our image data generators\n",
    "train_datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 930,
     "status": "ok",
     "timestamp": 1614719387598,
     "user": {
      "displayName": "Eli Gnesin",
      "photoUrl": "",
      "userId": "07665627688771215674"
     },
     "user_tz": 300
    },
    "id": "UAm5dKEUMRA7",
    "outputId": "65225841-a2b7-43b5-f4e5-89fa0380b7b4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /sciclone/home20/ejgnesin/.local/bora/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /sciclone/home20/ejgnesin/.local/bora/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 6, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 6, 6, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               590080    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 1,799,399\n",
      "Trainable params: 1,797,479\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#We're going to build a basic CNN using Keras Sequential models\n",
    "reg = l2(.001)\n",
    "model = Sequential()\n",
    "#Block-1 \n",
    "model.add(Conv2D(32,(3,3),padding='same', kernel_initializer='he_normal',\n",
    "                 kernel_regularizer = reg, input_shape=(img_rows,img_cols,1), activation = 'elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32,(3,3),padding='same', kernel_initializer='he_normal',\n",
    "                 kernel_regularizer = reg, input_shape=(img_rows,img_cols,1), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "#Block-2\n",
    "model.add(Conv2D(64,(3,3),padding='same', kernel_initializer='he_normal',\n",
    "                 kernel_regularizer = reg, activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64,(3,3),padding='same', kernel_initializer='he_normal',\n",
    "                 kernel_regularizer = reg, activation = 'elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "#Block-3\n",
    "model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal',\n",
    "                 kernel_regularizer = reg, activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal',\n",
    "                 kernel_regularizer = reg, activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "#Block-4\n",
    "model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal', \n",
    "                 activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal', \n",
    "                 activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "#Block-5\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,kernel_initializer='he_normal', activation='elu'))\n",
    "model.add(Dense(128,kernel_initializer='he_normal', activation='elu'))\n",
    "model.add(Dropout(0.5))\n",
    "#Block-6\n",
    "#model.add(Dense(32,kernel_initializer='he_normal', activation='elu'))\n",
    "#model.add(Dense(16,kernel_initializer='he_normal', activation='elu'))\n",
    "#model.add(Dropout(0.5))\n",
    "#Block-7\n",
    "model.add(Dense(num_classes,kernel_initializer='he_normal', activation='softmax'))\n",
    "#Show a summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "CctrnwnVM8Lr"
   },
   "outputs": [],
   "source": [
    "#Create some callbacks for use during training\n",
    "#This came straight from the article, I didn't change anything here\n",
    "checkpoint = ModelCheckpoint('EmotionDetectionModel_v20.h5',\n",
    "                             monitor='val_loss',\n",
    "                             mode='min',\n",
    "                             save_best_only=True,\n",
    "                             verbose=1)\n",
    "earlystop = EarlyStopping(monitor='val_loss',\n",
    "                          min_delta=0,\n",
    "                          patience=4,\n",
    "                          verbose=1,\n",
    "                          restore_best_weights=True\n",
    "                          )\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.2,\n",
    "                              patience=3,\n",
    "                              verbose=1,\n",
    "                              min_delta=0.0001)\n",
    "callbacks = [checkpoint,earlystop,reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tr0sHbcINawo",
    "outputId": "a1f12521-baf3-4d80-fb57-bda6a283c097",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /sciclone/home20/ejgnesin/.local/bora/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/93\n"
     ]
    }
   ],
   "source": [
    "#Now, we'll compile and fit the model\n",
    "opt = Adam()\n",
    "model.compile(optimizer = opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Now fit the model with fit\n",
    "nb_train_samples = 28709\n",
    "nb_validation_samples = 3589\n",
    "epochs= 93\n",
    "history=model.fit(\n",
    " X_train, y_train,\n",
    " steps_per_epoch=nb_train_samples//batch_size,\n",
    " epochs=epochs,\n",
    " callbacks=callbacks,\n",
    " validation_data=(X_val, y_val),\n",
    " validation_steps = nb_validation_samples//batch_size)\n",
    "model.save('makeathon_model_v20(l2reg-Dropout25-BS64-256x2-biggen).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fkixy5cbL0Tw"
   },
   "outputs": [],
   "source": [
    "#Plot the training and validation loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.savefig('loss_v20.png',bbox_inches= 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BGuAzh89L2av"
   },
   "outputs": [],
   "source": [
    "#Plot the training and validation accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='lower right')\n",
    "plt.savefig('accuracy_v20.png',bbox_inches= 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMipHkLgK8LPQle5/6IvJZR",
   "collapsed_sections": [],
   "mount_file_id": "1716CCsLLr088E2ncee6G1kgIjmnx-2Od",
   "name": "Makeathon Model Code.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
